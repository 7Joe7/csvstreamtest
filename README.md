# csvstreamer

## How to run

Should work out of the box - run with `docker-compose up -d mysql consul` and after the two are ready run `docker-compose up -d --build csvreader dbamanager`.

## Solution

I aimed for scalability and clean architecture. I used stream to allow for big data files. The technologies used are
a bit overkill for the project size but if we wanted to make the project bigger then I believe they are ideal.

I didn't manage to implement tests. I have spent more then 2 hours on the assignment learning along the way 
so whatever the result I am quite happy with what I have learned. If I was to implement tests yet then I would add unit tests
to service layers of the 2 services and made a one integration test with adding a .tar into the folder and testing inputs in DB. 
Also a feature to wait for consul and mysql startup is missing, 
it would be nice to use wait-for-it.sh wrapper to be able to start all with single `docker-compose up -d`.

Grpc service and protobuf messages are generated by these commands:
 
 `protoc -I=. --go_out=plugins=grpc:$GOPATH/src ./common/message/*` 
 `protoc-go-inject-tag -input=./common/model/client.pb.go`
 `protoc -I=. --go_out=plugins=grpc:$GOPATH/src ./common/service/*`
 
There is a common package with common code. Everything is vendored. There is also a git hooks setup which I consider a good practice. 
I would also consider putting there go vet and go meta linter.
 
## Update

Added unit tests to csvreader service folder, the dbmanager service tests I would do in a similar fashion - repository mocked.
For generating mocks I use mockery.

 `mockery -dir ./common/rpc -name ImporterClient -output ./csvreader/service/mocks`
 `mockery -dir ./common/rpc -name Importer_ImportClientsClient -output ./csvreader/service/mocks`
 `mockery -dir ./csvreader/service -name ImportSrc -output ./csvreader/service/mocks`
  
Added makefile with basic targets and improved starting of the Consul.
 